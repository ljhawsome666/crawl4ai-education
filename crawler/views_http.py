# crawler/views_http.py â€”â€” æä¾›ç”¨äº HTTP API çš„è§†å›¾å‡½æ•°
import json
from django.http import JsonResponse, FileResponse, Http404
from django.views.decorators.csrf import csrf_exempt
import os
from .views import run_crawler
from crawler.models import CrawlResultShowcase
from asgiref.sync import async_to_sync
from django.conf import settings


@csrf_exempt
def crawl_and_filter(request):
    if request.method != 'POST':
        return JsonResponse({'error': 'ä»…æ”¯æŒPOSTè¯·æ±‚'}, status=405)
    try:
        data = json.loads(request.body)

        url = data.get('url')
        keyword = data.get('keyword')

        # ğŸ”§ å‚æ•°è§£æ + é»˜è®¤å€¼è®¾ç½®
        max_depth = int(data.get('max_depth', 1))
        include_external = bool(data.get('include_external', False))
        strategy = data.get('strategy', 'bfs').lower()

        if not url or not keyword:
            return JsonResponse({'error': 'å‚æ•°ç¼ºå¤±'}, status=400)

        # âœ… è°ƒç”¨çˆ¬è™«ä¸»å‡½æ•°
        result = async_to_sync(run_crawler)(
            url, keyword,
            max_depth=max_depth,
            include_external=include_external,
            strategy=strategy
        )

        return JsonResponse(result)
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)




def download_file(request, filename):
    file_path = os.path.join(settings.BASE_DIR, 'output_files', filename)
    if not os.path.exists(file_path):
        raise Http404("æ–‡ä»¶ä¸å­˜åœ¨")
    return FileResponse(open(file_path, 'rb'), content_type='text/markdown; charset=utf-8')


def list_showcases(request):
    data = CrawlResultShowcase.objects.all().order_by('-created_at')
    result = [{
        'url': item.url,
        'keyword': item.keyword,
        'content_preview': item.content_preview,
    } for item in data]
    return JsonResponse(result, safe=False)
